{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilkobert.json\t\tkcelectra-base-dev-1025k.json\r\n",
      "exkcbert-paws.json\t\tkcelectra-base-dev-500k.json\r\n",
      "hanbert.json\t\t\tkcelectra-base-dev-700k.json\r\n",
      "kcbert-base.json\t\tkcelectra-base-dev-900k.json\r\n",
      "kcbert-large.json\t\tkcelectra-base-v1.json\r\n",
      "KcELECTRA-base-50135-100k.json\tkobert.json\r\n",
      "KcELECTRA-base-50135-200k.json\tkoelectra-base.json\r\n",
      "KcELECTRA-base-50135-300k.json\tkoelectra-base-v2.json\r\n",
      "KcELECTRA-base-50135-400k.json\tkoelectra-small.json\r\n",
      "KcELECTRA-base-50135-500k.json\tkoelectra-small-v2.json\r\n",
      "KcELECTRA-base-50135-848k.json\txlm-roberta.json\r\n",
      "kcelectra-base-dev-1000k.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls kornli/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"task\": \"kornli\",\r\n",
      "  \"data_dir\": \"data\",\r\n",
      "  \"ckpt_dir\": \"ckpt\",\r\n",
      "  \"train_file\": \"multinli.train.ko.tsv\",\r\n",
      "  \"dev_file\": \"xnli.dev.ko.tsv\",\r\n",
      "  \"test_file\": \"xnli.test.ko.tsv\",\r\n",
      "  \"evaluate_test_during_training\": false,\r\n",
      "  \"eval_all_checkpoints\": true,\r\n",
      "  \"save_optimizer\": false,\r\n",
      "  \"do_lower_case\": false,\r\n",
      "  \"do_train\": true,\r\n",
      "  \"do_eval\": true,\r\n",
      "  \"max_seq_len\": 72,\r\n",
      "  \"num_train_epochs\": 10,\r\n",
      "  \"weight_decay\": 0.0,\r\n",
      "  \"gradient_accumulation_steps\": 1,\r\n",
      "  \"adam_epsilon\": 1e-8,\r\n",
      "  \"warmup_steps\": 0,\r\n",
      "  \"max_steps\": -1,\r\n",
      "  \"max_grad_norm\": 1.0,\r\n",
      "  \"no_cuda\": false,\r\n",
      "  \"model_type\": \"kcbert\",\r\n",
      "  \"model_name_or_path\": \"beomi/kcbert-base\",\r\n",
      "  \"output_dir\": \"kcbert-kornli-ckpt\",\r\n",
      "  \"seed\": 42,\r\n",
      "  \"train_batch_size\": 128,\r\n",
      "  \"eval_batch_size\": 256,\r\n",
      "  \"logging_steps\": 3000,\r\n",
      "  \"save_steps\": 3000,\r\n",
      "  \"learning_rate\": 3e-5\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat kornli/kcbert-base.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./kornli/kcbert-base.json',\n",
       " './nsmc/kcbert-base.json',\n",
       " './korsts/kcbert-base.json',\n",
       " './naver-ner/kcbert-base.json',\n",
       " './korquad/kcbert-base.json',\n",
       " './question-pair/kcbert-base.json',\n",
       " './paws/kcbert-base.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('./*/kcbert-base.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilkobert.json\t\tkcelectra-base-dev-1025k.json\r\n",
      "exkcbert-paws.json\t\tkcelectra-base-dev-500k.json\r\n",
      "hanbert.json\t\t\tkcelectra-base-dev-700k.json\r\n",
      "kcbert-base.json\t\tkcelectra-base-dev-900k.json\r\n",
      "kcbert-large.json\t\tkcelectra-base-v1.json\r\n",
      "KcELECTRA-base-50135-100k.json\tkobert.json\r\n",
      "KcELECTRA-base-50135-200k.json\tkoelectra-base.json\r\n",
      "KcELECTRA-base-50135-300k.json\tkoelectra-base-v2.json\r\n",
      "KcELECTRA-base-50135-400k.json\tkoelectra-small.json\r\n",
      "KcELECTRA-base-50135-500k.json\tkoelectra-small-v2.json\r\n",
      "KcELECTRA-base-50135-848k.json\txlm-roberta.json\r\n",
      "kcelectra-base-dev-1000k.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./paws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"task\": \"paws\",\r\n",
      "  \"data_dir\": \"data\",\r\n",
      "  \"ckpt_dir\": \"ckpt\",\r\n",
      "  \"train_file\": \"translated_train.tsv\",\r\n",
      "  \"dev_file\": \"dev_2k.tsv\",\r\n",
      "  \"test_file\": \"test_2k.tsv\",\r\n",
      "  \"evaluate_test_during_training\": false,\r\n",
      "  \"eval_all_checkpoints\": true,\r\n",
      "  \"save_optimizer\": false,\r\n",
      "  \"do_lower_case\": false,\r\n",
      "  \"do_train\": true,\r\n",
      "  \"do_eval\": true,\r\n",
      "  \"max_seq_len\": 128,\r\n",
      "  \"num_train_epochs\": 15,\r\n",
      "  \"weight_decay\": 0.0,\r\n",
      "  \"gradient_accumulation_steps\": 1,\r\n",
      "  \"adam_epsilon\": 1e-08,\r\n",
      "  \"warmup_steps\": 0,\r\n",
      "  \"max_steps\": -1,\r\n",
      "  \"max_grad_norm\": 1.0,\r\n",
      "  \"no_cuda\": false,\r\n",
      "  \"model_type\": \"exbert\",\r\n",
      "  \"model_name_or_path\": \"beomi/exKcBERT-paws\",\r\n",
      "  \"output_dir\": \"exkcbert-paws-ckpt\",\r\n",
      "  \"seed\": 42,\r\n",
      "  \"train_batch_size\": 32,\r\n",
      "  \"eval_batch_size\": 64,\r\n",
      "  \"logging_steps\": 1000,\r\n",
      "  \"save_steps\": 1000,\r\n",
      "  \"learning_rate\": 3e-05\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ./paws/exkcbert-paws.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for original in glob('./*/kcbert-base.json'):\n",
    "#     config = json.load(open(original))\n",
    "#     config['model_name_or_path'] = 'beomi/exKcBERT-paws'\n",
    "#     config['model_type'] = 'exbert'\n",
    "#     config['output_dir'] = config['output_dir'].replace('kcbert-base', 'exKcBERT').lower()\n",
    "#     pprint(config)\n",
    "#     new_path = original.replace('kcbert-base', 'exKcBERT-paws').lower()\n",
    "#     print(new_path)\n",
    "#     json.dump(config, open(new_path, 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'dev_file': 'xnli.dev.ko.tsv',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 256,\n",
      " 'evaluate_test_during_training': False,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 3e-05,\n",
      " 'logging_steps': 3000,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_seq_len': 72,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 10,\n",
      " 'output_dir': 'kcbert-kornli-ckpt',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 3000,\n",
      " 'seed': 42,\n",
      " 'task': 'kornli',\n",
      " 'test_file': 'xnli.test.ko.tsv',\n",
      " 'train_batch_size': 128,\n",
      " 'train_file': 'multinli.train.ko.tsv',\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./kornli/exkcbert-kowiki.json\n",
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'dev_file': '',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 128,\n",
      " 'evaluate_test_during_training': True,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 5e-05,\n",
      " 'logging_steps': 2000,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_seq_len': 50,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 8,\n",
      " 'output_dir': 'exkcbert-kowiki-nsmc-ckpt',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 2000,\n",
      " 'seed': 42,\n",
      " 'task': 'nsmc',\n",
      " 'test_file': 'ratings_test.txt',\n",
      " 'train_batch_size': 64,\n",
      " 'train_file': 'ratings_train.txt',\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./nsmc/exkcbert-kowiki.json\n",
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'dev_file': 'sts-dev.tsv',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 64,\n",
      " 'evaluate_test_during_training': False,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 5e-05,\n",
      " 'logging_steps': 100,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_seq_len': 72,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 5,\n",
      " 'output_dir': 'exkcbert-kowiki-korsts-ckpt',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 100,\n",
      " 'seed': 42,\n",
      " 'task': 'korsts',\n",
      " 'test_file': 'sts-test.tsv',\n",
      " 'train_batch_size': 32,\n",
      " 'train_file': 'sts-train.tsv',\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./korsts/exkcbert-kowiki.json\n",
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'dev_file': '',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 128,\n",
      " 'evaluate_test_during_training': True,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 8e-05,\n",
      " 'logging_steps': 1000,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_seq_len': 50,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 20,\n",
      " 'output_dir': 'exkcbert-kowiki-naver-ner-ckpt',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 1000,\n",
      " 'seed': 42,\n",
      " 'task': 'naver-ner',\n",
      " 'test_file': 'test.tsv',\n",
      " 'train_batch_size': 64,\n",
      " 'train_file': 'train.tsv',\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./naver-ner/exkcbert-kowiki.json\n",
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'do_eval': False,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'doc_stride': 128,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 32,\n",
      " 'evaluate_during_training': True,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 5e-05,\n",
      " 'logging_steps': 2000,\n",
      " 'max_answer_length': 30,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_query_length': 64,\n",
      " 'max_seq_length': 300,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'n_best_size': 20,\n",
      " 'no_cuda': False,\n",
      " 'null_score_diff_threshold': 0.0,\n",
      " 'num_train_epochs': 5,\n",
      " 'output_dir': 'exkcbert-kowiki-korquad-ckpt',\n",
      " 'overwrite_output_dir': True,\n",
      " 'predict_file': 'KorQuAD_v1.0_dev.json',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 2000,\n",
      " 'seed': 42,\n",
      " 'task': 'korquad',\n",
      " 'threads': 4,\n",
      " 'train_batch_size': 16,\n",
      " 'train_file': 'KorQuAD_v1.0_train.json',\n",
      " 'verbose_logging': True,\n",
      " 'version_2_with_negative': False,\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./korquad/exkcbert-kowiki.json\n",
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'dev_file': 'dev.tsv',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 64,\n",
      " 'evaluate_test_during_training': False,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 5e-05,\n",
      " 'logging_steps': 100,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_seq_len': 72,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 5,\n",
      " 'output_dir': 'exkcbert-kowiki-question-pair-ckpt',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 100,\n",
      " 'seed': 42,\n",
      " 'task': 'question-pair',\n",
      " 'test_file': 'test.tsv',\n",
      " 'train_batch_size': 32,\n",
      " 'train_file': 'train.tsv',\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./question-pair/exkcbert-kowiki.json\n",
      "{'adam_epsilon': 1e-08,\n",
      " 'ckpt_dir': 'ckpt',\n",
      " 'data_dir': 'data',\n",
      " 'dev_file': 'dev_2k.tsv',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': True,\n",
      " 'eval_all_checkpoints': True,\n",
      " 'eval_batch_size': 64,\n",
      " 'evaluate_test_during_training': False,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 3e-05,\n",
      " 'logging_steps': 1000,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_seq_len': 128,\n",
      " 'max_steps': -1,\n",
      " 'model_name_or_path': 'beomi/exKcBERT-kowiki',\n",
      " 'model_type': 'exbert',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 15,\n",
      " 'output_dir': 'exkcbert-kowiki-paws-ckpt',\n",
      " 'save_optimizer': False,\n",
      " 'save_steps': 1000,\n",
      " 'seed': 42,\n",
      " 'task': 'paws',\n",
      " 'test_file': 'test_2k.tsv',\n",
      " 'train_batch_size': 32,\n",
      " 'train_file': 'translated_train.tsv',\n",
      " 'warmup_steps': 0,\n",
      " 'weight_decay': 0.0}\n",
      "./paws/exkcbert-kowiki.json\n"
     ]
    }
   ],
   "source": [
    "for original in glob('./*/kcbert-base.json'):\n",
    "    config = json.load(open(original))\n",
    "    config['model_name_or_path'] = 'beomi/exKcBERT-kowiki'\n",
    "    config['model_type'] = 'exbert'\n",
    "    config['output_dir'] = config['output_dir'].replace('kcbert-base', 'exKcBERT-kowiki').lower()\n",
    "    pprint(config)\n",
    "    new_path = original.replace('kcbert-base', 'exKcBERT-kowiki').lower()\n",
    "    print(new_path)\n",
    "    json.dump(config, open(new_path, 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
